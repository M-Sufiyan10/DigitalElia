{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GhQ320h6uB1H",
        "outputId": "db2c10d0-50f1-4dd6-d896-09353597ffbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               shers\n",
            "0  aaj  ik  aur  baras  biit  gayā  us  ke  baġha...\n",
            "1  mujhe  duniyā  ke  ta.anoñ  par  kabhī  ġhussa...\n",
            "2  mujhe  duniya  ke  tanon  par  kabhi  ghussa  ...\n",
            "3  aaj  ik  aur  baras  biit  gayā  us  ke  baġha...\n",
            "4  miir  kyā  saade  haiñ  bīmār  hue  jis  ke  s...\n",
            "Index(['shers'], dtype='object')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.0401 - loss: 7.1344 - val_accuracy: 0.0318 - val_loss: 6.9761\n",
            "Epoch 2/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.0385 - loss: 6.7230 - val_accuracy: 0.0318 - val_loss: 7.1343\n",
            "Epoch 3/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.0393 - loss: 6.6743 - val_accuracy: 0.0450 - val_loss: 6.9345\n",
            "Epoch 4/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.0577 - loss: 6.4246 - val_accuracy: 0.0584 - val_loss: 6.9168\n",
            "Epoch 5/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.0683 - loss: 6.2811 - val_accuracy: 0.0636 - val_loss: 6.9743\n",
            "Epoch 6/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.0777 - loss: 6.0860 - val_accuracy: 0.0638 - val_loss: 7.0342\n",
            "Epoch 7/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.0823 - loss: 6.0460 - val_accuracy: 0.0630 - val_loss: 7.1371\n",
            "Epoch 8/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.0864 - loss: 5.9281 - val_accuracy: 0.0689 - val_loss: 7.3055\n",
            "Epoch 9/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.0957 - loss: 5.8328 - val_accuracy: 0.0649 - val_loss: 7.3521\n",
            "Epoch 10/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.0969 - loss: 5.7317 - val_accuracy: 0.0714 - val_loss: 7.4841\n",
            "Epoch 11/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.1080 - loss: 5.5822 - val_accuracy: 0.0784 - val_loss: 7.6793\n",
            "Epoch 12/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.1173 - loss: 5.5102 - val_accuracy: 0.0813 - val_loss: 7.7868\n",
            "Epoch 13/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.1209 - loss: 5.4200 - val_accuracy: 0.0846 - val_loss: 7.8702\n",
            "Epoch 14/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.1245 - loss: 5.3112 - val_accuracy: 0.0813 - val_loss: 8.0542\n",
            "Epoch 15/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.1277 - loss: 5.2142 - val_accuracy: 0.0867 - val_loss: 8.2059\n",
            "Epoch 16/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.1366 - loss: 5.1100 - val_accuracy: 0.0894 - val_loss: 8.1931\n",
            "Epoch 17/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.1426 - loss: 5.0068 - val_accuracy: 0.0830 - val_loss: 8.4381\n",
            "Epoch 18/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.1511 - loss: 4.8860 - val_accuracy: 0.0878 - val_loss: 8.9409\n",
            "Epoch 19/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.1583 - loss: 4.7988 - val_accuracy: 0.0840 - val_loss: 9.0220\n",
            "Epoch 20/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.1687 - loss: 4.6691 - val_accuracy: 0.0854 - val_loss: 9.2167\n",
            "Epoch 21/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.1771 - loss: 4.5667 - val_accuracy: 0.0848 - val_loss: 9.5892\n",
            "Epoch 22/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.1843 - loss: 4.4935 - val_accuracy: 0.0848 - val_loss: 9.7569\n",
            "Epoch 23/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.1951 - loss: 4.3862 - val_accuracy: 0.0824 - val_loss: 10.2538\n",
            "Epoch 24/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.2105 - loss: 4.2374 - val_accuracy: 0.0862 - val_loss: 10.6217\n",
            "Epoch 25/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.2182 - loss: 4.1465 - val_accuracy: 0.0908 - val_loss: 10.9685\n",
            "Epoch 26/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.2326 - loss: 4.0348 - val_accuracy: 0.0889 - val_loss: 11.3457\n",
            "Epoch 27/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.2434 - loss: 3.9272 - val_accuracy: 0.0916 - val_loss: 11.9370\n",
            "Epoch 28/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.2570 - loss: 3.7999 - val_accuracy: 0.0926 - val_loss: 12.1045\n",
            "Epoch 29/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.2732 - loss: 3.6778 - val_accuracy: 0.0935 - val_loss: 12.5649\n",
            "Epoch 30/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.2855 - loss: 3.5670 - val_accuracy: 0.0908 - val_loss: 13.0899\n",
            "Epoch 31/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.3039 - loss: 3.4185 - val_accuracy: 0.0972 - val_loss: 12.9559\n",
            "Epoch 32/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.3245 - loss: 3.2875 - val_accuracy: 0.0961 - val_loss: 13.7560\n",
            "Epoch 33/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.3367 - loss: 3.1815 - val_accuracy: 0.0948 - val_loss: 14.4022\n",
            "Epoch 34/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.3473 - loss: 3.1107 - val_accuracy: 0.0991 - val_loss: 14.8604\n",
            "Epoch 35/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.3696 - loss: 2.9801 - val_accuracy: 0.1013 - val_loss: 15.1838\n",
            "Epoch 36/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.3820 - loss: 2.8943 - val_accuracy: 0.0994 - val_loss: 15.5046\n",
            "Epoch 37/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.4037 - loss: 2.7942 - val_accuracy: 0.0999 - val_loss: 15.5450\n",
            "Epoch 38/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.4138 - loss: 2.6973 - val_accuracy: 0.1013 - val_loss: 16.5818\n",
            "Epoch 39/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.4289 - loss: 2.6312 - val_accuracy: 0.1015 - val_loss: 17.0339\n",
            "Epoch 40/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.4436 - loss: 2.5296 - val_accuracy: 0.1026 - val_loss: 16.8658\n",
            "Epoch 41/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.4607 - loss: 2.4396 - val_accuracy: 0.1064 - val_loss: 17.4836\n",
            "Epoch 42/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.4788 - loss: 2.3582 - val_accuracy: 0.1056 - val_loss: 17.8695\n",
            "Epoch 43/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.4851 - loss: 2.2879 - val_accuracy: 0.1083 - val_loss: 18.2286\n",
            "Epoch 44/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.5036 - loss: 2.2011 - val_accuracy: 0.1083 - val_loss: 18.6952\n",
            "Epoch 45/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.5145 - loss: 2.1629 - val_accuracy: 0.1091 - val_loss: 19.2436\n",
            "Epoch 46/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.5262 - loss: 2.0683 - val_accuracy: 0.1080 - val_loss: 19.0931\n",
            "Epoch 47/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.5427 - loss: 1.9936 - val_accuracy: 0.1118 - val_loss: 19.9541\n",
            "Epoch 48/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.5513 - loss: 1.9464 - val_accuracy: 0.1107 - val_loss: 19.6434\n",
            "Epoch 49/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.5563 - loss: 1.9175 - val_accuracy: 0.1137 - val_loss: 20.1073\n",
            "Epoch 50/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.5729 - loss: 1.8395 - val_accuracy: 0.1174 - val_loss: 20.6859\n",
            "Epoch 51/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.5843 - loss: 1.7777 - val_accuracy: 0.1163 - val_loss: 20.7503\n",
            "Epoch 52/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.5869 - loss: 1.7597 - val_accuracy: 0.1118 - val_loss: 21.2111\n",
            "Epoch 53/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.6082 - loss: 1.6712 - val_accuracy: 0.1163 - val_loss: 21.4552\n",
            "Epoch 54/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.6072 - loss: 1.6440 - val_accuracy: 0.1209 - val_loss: 21.9460\n",
            "Epoch 55/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.6172 - loss: 1.6036 - val_accuracy: 0.1198 - val_loss: 22.0635\n",
            "Epoch 56/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.6382 - loss: 1.5226 - val_accuracy: 0.1244 - val_loss: 22.4589\n",
            "Epoch 57/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.6348 - loss: 1.5174 - val_accuracy: 0.1180 - val_loss: 22.8097\n",
            "Epoch 58/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.6530 - loss: 1.4395 - val_accuracy: 0.1215 - val_loss: 23.0026\n",
            "Epoch 59/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.6640 - loss: 1.3916 - val_accuracy: 0.1212 - val_loss: 23.5164\n",
            "Epoch 60/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - accuracy: 0.6689 - loss: 1.3765 - val_accuracy: 0.1228 - val_loss: 23.4974\n",
            "Epoch 61/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.6695 - loss: 1.3540 - val_accuracy: 0.1220 - val_loss: 24.1189\n",
            "Epoch 62/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.6868 - loss: 1.2800 - val_accuracy: 0.1277 - val_loss: 24.0652\n",
            "Epoch 63/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.6941 - loss: 1.2583 - val_accuracy: 0.1263 - val_loss: 24.1635\n",
            "Epoch 64/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.6881 - loss: 1.2658 - val_accuracy: 0.1290 - val_loss: 23.9587\n",
            "Epoch 65/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.6945 - loss: 1.2296 - val_accuracy: 0.1263 - val_loss: 24.3027\n",
            "Epoch 66/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.7060 - loss: 1.1725 - val_accuracy: 0.1298 - val_loss: 24.9177\n",
            "Epoch 67/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7162 - loss: 1.1398 - val_accuracy: 0.1274 - val_loss: 24.8654\n",
            "Epoch 68/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.7253 - loss: 1.1085 - val_accuracy: 0.1269 - val_loss: 25.6823\n",
            "Epoch 69/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7292 - loss: 1.0746 - val_accuracy: 0.1287 - val_loss: 25.6792\n",
            "Epoch 70/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.7298 - loss: 1.0799 - val_accuracy: 0.1336 - val_loss: 25.5279\n",
            "Epoch 71/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.7384 - loss: 1.0299 - val_accuracy: 0.1306 - val_loss: 26.3536\n",
            "Epoch 72/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - accuracy: 0.7483 - loss: 1.0142 - val_accuracy: 0.1293 - val_loss: 26.4269\n",
            "Epoch 73/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.7487 - loss: 0.9838 - val_accuracy: 0.1341 - val_loss: 26.4423\n",
            "Epoch 74/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7498 - loss: 0.9727 - val_accuracy: 0.1339 - val_loss: 27.2666\n",
            "Epoch 75/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.7637 - loss: 0.9346 - val_accuracy: 0.1341 - val_loss: 26.7551\n",
            "Epoch 76/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.7665 - loss: 0.9246 - val_accuracy: 0.1355 - val_loss: 27.5523\n",
            "Epoch 77/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - accuracy: 0.7736 - loss: 0.8783 - val_accuracy: 0.1360 - val_loss: 27.1783\n",
            "Epoch 78/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7760 - loss: 0.8871 - val_accuracy: 0.1349 - val_loss: 28.1739\n",
            "Epoch 79/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.7757 - loss: 0.8728 - val_accuracy: 0.1374 - val_loss: 27.5938\n",
            "Epoch 80/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7775 - loss: 0.8679 - val_accuracy: 0.1339 - val_loss: 28.1678\n",
            "Epoch 81/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.7869 - loss: 0.8230 - val_accuracy: 0.1355 - val_loss: 28.1483\n",
            "Epoch 82/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.7855 - loss: 0.8335 - val_accuracy: 0.1368 - val_loss: 27.9501\n",
            "Epoch 83/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.7978 - loss: 0.7875 - val_accuracy: 0.1368 - val_loss: 28.3431\n",
            "Epoch 84/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.7901 - loss: 0.8015 - val_accuracy: 0.1379 - val_loss: 29.1410\n",
            "Epoch 85/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.8011 - loss: 0.7557 - val_accuracy: 0.1403 - val_loss: 28.7951\n",
            "Epoch 86/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.7993 - loss: 0.7674 - val_accuracy: 0.1379 - val_loss: 29.2260\n",
            "Epoch 87/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.8041 - loss: 0.7535 - val_accuracy: 0.1379 - val_loss: 29.0478\n",
            "Epoch 88/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.8035 - loss: 0.7484 - val_accuracy: 0.1384 - val_loss: 29.2467\n",
            "Epoch 89/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.8124 - loss: 0.7108 - val_accuracy: 0.1390 - val_loss: 29.9381\n",
            "Epoch 90/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.8167 - loss: 0.7025 - val_accuracy: 0.1403 - val_loss: 29.8678\n",
            "Epoch 91/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.8153 - loss: 0.6951 - val_accuracy: 0.1365 - val_loss: 29.9519\n",
            "Epoch 92/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.8251 - loss: 0.6659 - val_accuracy: 0.1419 - val_loss: 29.8460\n",
            "Epoch 93/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8114 - loss: 0.7055 - val_accuracy: 0.1365 - val_loss: 29.8872\n",
            "Epoch 94/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - accuracy: 0.8280 - loss: 0.6458 - val_accuracy: 0.1376 - val_loss: 29.7168\n",
            "Epoch 95/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.8237 - loss: 0.6554 - val_accuracy: 0.1422 - val_loss: 30.2064\n",
            "Epoch 96/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8367 - loss: 0.6118 - val_accuracy: 0.1425 - val_loss: 30.5573\n",
            "Epoch 97/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8367 - loss: 0.6168 - val_accuracy: 0.1409 - val_loss: 31.0076\n",
            "Epoch 98/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.8315 - loss: 0.6260 - val_accuracy: 0.1465 - val_loss: 30.7552\n",
            "Epoch 99/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.8370 - loss: 0.6057 - val_accuracy: 0.1414 - val_loss: 31.0360\n",
            "Epoch 100/100\n",
            "\u001b[1m1045/1045\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.8475 - loss: 0.5726 - val_accuracy: 0.1433 - val_loss: 31.4157\n",
            "mohabbat ik basā hai jaoge āñkhoñ ko lagā nahīñ rahtā hai to\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/cleaned_filtered_poetry.csv')\n",
        "\n",
        "# Inspect the dataset\n",
        "print(df.head())\n",
        "print(df.columns)\n",
        "\n",
        "# Clean the dataset (assuming there might be missing values)\n",
        "df.dropna(inplace=True)\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# Assuming the poetry column contains the text (update this as needed)\n",
        "poetry_column = df.columns[0]  # Update if necessary\n",
        "poetry = df[poetry_column].astype(str).tolist()\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(poetry)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Create input sequences\n",
        "input_sequences = []\n",
        "for line in poetry:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences\n",
        "max_sequence_len = 100\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
        "\n",
        "# Split input and output\n",
        "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# Build GRU Model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(GRU(150, return_sequences=True))\n",
        "model.add(GRU(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "batch_size=32\n",
        "# Train the model\n",
        "history = model.fit(X, y, epochs=100, verbose=1,batch_size=batch_size,validation_split=0.1)\n",
        "\n",
        "# Function to generate poetry\n",
        "def generate_poetry(seed_text, next_words=20):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# Example usage\n",
        "seed_text = \"mohabbat ik\"\n",
        "print(generate_poetry(seed_text, next_words=10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ6MRARKuR8o",
        "outputId": "2468ede0-cb4f-4370-876e-233594cafb2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('/content/roman_urdu_poetry_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG9u3YK5uTxX",
        "outputId": "6d6576b0-0a87-4e53-94fc-3b26f28f223d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('/conteroman_urdu_poetry_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "qryQP88LuYYD",
        "outputId": "beb79443-0946-4e7b-ace4-423eb9a6aa89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://056566ac8da03440ba.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://056566ac8da03440ba.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Function to generate poetry\n",
        "def generate_poetry(seed_text, next_words=20):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# Create Gradio Interface\n",
        "gr.Interface(\n",
        "    fn=generate_poetry,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Enter Seed Text\"),\n",
        "        gr.Slider(minimum=10, maximum=30, step=1,label=\"Select Poetry Length\")  # Slider added\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Generated Poetry\"),\n",
        "    title=\"Roman Urdu Poetry Generator\",\n",
        "    description=\"Enter a seed phrase, select the length of the poetry, and generate a poem in Roman Urdu.\"\n",
        ").launch(share=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tpqz60u-uc0P"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Using cached streamlit-1.42.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting altair<6,>=4.0 (from streamlit)\n",
            "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
            "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting cachetools<6,>=4.0 (from streamlit)\n",
            "  Using cached cachetools-5.5.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting click<9,>=7.0 (from streamlit)\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in ./env/lib/python3.12/site-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in ./env/lib/python3.12/site-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in ./env/lib/python3.12/site-packages (from streamlit) (2.2.3)\n",
            "Collecting pillow<12,>=7.1.0 (from streamlit)\n",
            "  Using cached pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in ./env/lib/python3.12/site-packages (from streamlit) (5.29.3)\n",
            "Collecting pyarrow>=7.0 (from streamlit)\n",
            "  Using cached pyarrow-19.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in ./env/lib/python3.12/site-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in ./env/lib/python3.12/site-packages (from streamlit) (13.9.4)\n",
            "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
            "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting toml<2,>=0.10.1 (from streamlit)\n",
            "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in ./env/lib/python3.12/site-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Using cached watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in ./env/lib/python3.12/site-packages (from streamlit) (6.4.2)\n",
            "Collecting jinja2 (from altair<6,>=4.0->streamlit)\n",
            "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
            "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
            "  Using cached narwhals-1.26.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./env/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./env/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./env/lib/python3.12/site-packages (from rich<14,>=10.14.0->streamlit) (2.19.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.12/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
            "  Using cached attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
            "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
            "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
            "  Using cached rpds_py-0.22.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./env/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in ./env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Using cached streamlit-1.42.0-py2.py3-none-any.whl (9.6 MB)\n",
            "Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
            "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
            "Using cached cachetools-5.5.1-py3-none-any.whl (9.5 kB)\n",
            "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
            "Using cached pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "Using cached pyarrow-19.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
            "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Using cached watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
            "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "Using cached narwhals-1.26.0-py3-none-any.whl (306 kB)\n",
            "Using cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
            "Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
            "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Using cached rpds_py-0.22.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
            "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, toml, tenacity, smmap, rpds-py, pyarrow, pillow, narwhals, jinja2, click, cachetools, blinker, attrs, referencing, pydeck, gitdb, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
            "Successfully installed altair-5.5.0 attrs-25.1.0 blinker-1.9.0 cachetools-5.5.1 click-8.1.8 gitdb-4.0.12 gitpython-3.1.44 jinja2-3.1.5 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 narwhals-1.26.0 pillow-11.1.0 pyarrow-19.0.0 pydeck-0.9.1 referencing-0.36.2 rpds-py-0.22.3 smmap-5.0.2 streamlit-1.42.0 tenacity-9.0.0 toml-0.10.2 watchdog-6.0.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "to=Tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<keras.src.legacy.preprocessing.text.Tokenizer object at 0x72cf2cb08230>\n"
          ]
        }
      ],
      "source": [
        "token=Tokenizer()\n",
        "print(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
